```{r libraries, include = F}
library(influxdbclient)
library(dplyr)
library(lubridate)
library(ggplot2)
library(tidyverse)
```



# READ IN DATA FROM GRAFANA AND METADATA
```{r grafana, include = F}
# You can generate an API token from the "API Tokens Tab" in the UI
token = "tu3zUeCazQobS4TrIIRftQS3Tr4xoZQoZaRf0Ve0iCrU4LZSY1jTS3laCJ_OjwJxWJ6WsKuwXN_tVV10R73hyg=="

client <- InfluxDBClient$new(url = "https://influx.smcs.abilium.io",
                             token = token,
                             org = "abilium")

# Adjust start time here!
start = "2023-05-15"
stop = "2023-09-16"

tables <- client$query(paste0('from(bucket: "smcs") |> range(start: ', start, ', stop: ', stop, ') |> filter(fn: (r) => r["_measurement"] == "mqtt_consumer") |> filter(fn: (r) => r["_field"] == "decoded_payload_temperature" or r["_field"] == "decoded_payload_humidity") |> filter(fn: (r) => r["topic"] != "v3/dynamicventilation@ttn/devices/eui-f613c9feff19276a/up") |> filter(fn: (r) => r["topic"] != "helium/eeea9617559b/rx") |> pivot(rowKey: ["_time"], columnKey: ["_field"], valueColumn: "_value")'))
```

```{r meta, include = F}
meta <- read_csv2("../data/metadata_network_2023.csv") |>
  dplyr::mutate(Start = dmy(Start))

# the replaced loggers are stored in meta_old
meta_old <- read_csv2("../data/metadata_network_old.csv") |>
  dplyr::mutate(Start = dmy(Start)) |>
  dplyr::mutate(End = dmy(End))
```



# DATA WRANGLING
```{r dataframes, include = F}
# Create empty two dataframes for all loggers
combined_T <- tibble(Time = as.POSIXct(character(), format = "%Y-%m-%d %H:%M"))
combined_RH <- tibble(Time = as.POSIXct(character(), format = "%Y-%m-%d %H:%M"))
# Store the missing loggers for further debugging
missing_loggers = c()
```

## Data from current loggers
```{r currentloggers, indlude = F}
# Combine all the loggers into one big table (separate for T and RH)
for (code in meta$Code_grafana) {

  # Get installation date of logger
  start <- meta$Start[which(meta$Code_grafana == code)]
  # Get the site name of the logger
  # comment out the following line if you want to use the codes instead
  log_name <- meta$STANDORT_NEU[which(meta$Code_grafana == code)]
  print(log_name)
  print(paste0("Logging since: ", start))

  found = F #variable to check if the logger was found in the grafana data

  for (x in 1:length(tables)) {

    if (code == tables[[x]]$name[1]) { #this is the right logger!
      found = T
      # clean data inside the individual loggers and round time to 10mins
      log_data <- tables[[x]] |>
        dplyr::select(time, decoded_payload_temperature, decoded_payload_humidity) |>
        dplyr::rename(RH = decoded_payload_humidity, Temp = decoded_payload_temperature, Time = time) |>
        dplyr::mutate(Time = ymd_hms(Time)) |>
        dplyr::mutate(Time = round_date(Time, unit="10 minutes")) |>
        group_by(Time) |>
        summarise(Temp = mean(Temp), RH = mean(RH)) |>
        filter(Time > start) #delete all the data before logger was installed at this site

      # separate the T and RH values
      log_data_T <- log_data |>
        dplyr::select(Time, Temp)

      log_data_RH <- log_data |>
        dplyr::select(Time, RH)

      # add data to the Temperature and RH tables by full join
      # rename the Temp / RH column with the logger's name
      combined_T <- combined_T |>
        full_join(log_data_T, by = "Time") |>
        rename_with(~ log_name, Temp)

      combined_RH <- combined_RH |>
        full_join(log_data_RH, by = "Time") |>
        rename_with(~ log_name, RH)
    }
  }
  if (found == F) {
    print("Logger not found")
    missing_loggers <- c(missing_loggers, log_name)}
}

print(missing_loggers)
```

## OPTIONAL: Add data from replaced loggers
```{r replacedloggers, include = F}
# Combine all the loggers into one big table (separate for T and RH)
for (code in meta_old$Code_grafana) {

  # Get installation date of logger
  start <- meta_old$Start[which(meta_old$Code_grafana == code)]
  end <- meta_old$End[which(meta_old$Code_grafana == code)]
  # Get the site name of the logger
  # comment out the following line if you want to use the codes instead
  log_name <- meta_old$STANDORT_NEU[which(meta_old$Code_grafana == code)]
  print(log_name)
  print(paste0("Was installed from: ", start, " to ", end))

  found = F #variable to check if the logger was found in the grafana data

  for (x in 1:length(tables)) {

    if (code == tables[[x]]$name[1]) { #this is the right logger!
      found = T
      # clean data inside the individual loggers and round time to 10mins
      log_data <- tables[[x]] |>
        dplyr::select(time, decoded_payload_temperature, decoded_payload_humidity) |>
        dplyr::rename(RH = decoded_payload_humidity, Temp = decoded_payload_temperature, Time = time) |>
        dplyr::mutate(Time = ymd_hms(Time)) |>
        dplyr::mutate(Time = round_date(Time, unit="10 minutes")) |>
        group_by(Time) |>
        summarise(Temp = mean(Temp), RH = mean(RH)) |>
        filter(Time > start) |>
        filter(Time < end) #delete all the data before logger was installed at this site

      # separate the T and RH values
      log_data_T <- log_data |>
        dplyr::select(Time, Temp)

      log_data_RH <- log_data |>
        dplyr::select(Time, RH)

      # add data to the Temperature and RH tables by left join
      # replace the data in the respective station by the logger data
      combined_T <- combined_T |>
      left_join(log_data_T |> select(Time, Temp), by = "Time") |>
      mutate({{ log_name }} := ifelse(!is.na(Temp), Temp, .data[[log_name]])) |>
      select(-Temp)  # Drop the Temp column if you no longer need it

      combined_RH <- combined_RH |>
      left_join(log_data_RH |> select(Time, RH), by = "Time") |>
      mutate({{ log_name }} := ifelse(!is.na(RH), RH, .data[[log_name]])) |>
      select(-RH)  # Drop the Temp column if you no longer need it
    }
  }
  if (found == F) {
    print("Logger not found")
    missing_loggers <- c(missing_loggers, log_name)}
}

print(missing_loggers)
```



# PLOTTING
```{r plots, include = T}
visdat::vis_miss(
  combined_T,
  cluster = FALSE, 
  warn_large_data = FALSE
  )

ggplot(data = combined_T, aes(x=Time)) +
  geom_line(aes(y = `Bundesplatz`, colour = 'Bundesplatz')) + # make sure to use these `` for site names with a space in between
  geom_line(aes(y = `Ostermundigen Oberfeld`, colour = 'Ostermundigen Oberfeld')) +
  geom_line(aes(y = `Monbijou-Park`, colour = 'Monbijou-Park')) +
  geom_line(aes(y = `Bollwerk`, colour = 'Bollwerk')) +
  labs(y = "Temperature [Â°C]")
```



# EXPORT
```{r}
# 1. Export any time range

# set your local directory
setwd("...")

write_csv(combined_T, paste0("T_all_loggers_", start,"-", end, ".csv"))
write_csv(combined_RH, paste0("RH_all_loggers_", start,"-", end, ".csv"))
```


```{r}
# 2. Export JJA and MJJAS (15. Mai-16.Sept) temperature tables for yearly report

write_csv(combined_T, ("../data/Rawdata_T_2023_MJJAS.csv"))

combined_T_JJA <- combined_T |>
  filter(month(Time) == c(6:8))

write_csv(combined_T_JJA, ("../data/Rawdata_T_2023_MJJAS.csv"))

```




